{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 33298,
     "status": "ok",
     "timestamp": 1749400471291,
     "user": {
      "displayName": "Rakibul Islam Rifat",
      "userId": "07268514922413816101"
     },
     "user_tz": -360
    },
    "id": "ws_I3APd3zJu",
    "outputId": "b154bd5d-d6d5-4d4f-c094-a28346be70e0"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ──────────────────────────────────────────────────────────────────────────────\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Step 01: (Re)Mount Google Drive\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# ──────────────────────────────────────────────────────────────────────────────\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[32m      5\u001b[39m drive.mount(\u001b[33m'\u001b[39m\u001b[33m/content/drive\u001b[39m\u001b[33m'\u001b[39m, force_remount=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# ──────────────────────────────────────────────────────────────────────────────\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Step 02: Set Working Directory\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# ──────────────────────────────────────────────────────────────────────────────\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Step 01: (Re)Mount Google Drive\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Step 02: Set Working Directory\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "import os\n",
    "data_dir = '/content/drive/MyDrive/ML Projects/SPD'\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "os.chdir(data_dir)\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Step 03: Install & Import Libraries \n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "#!pip install xgboost shap --quiet\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.cluster import KMeans\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "import shap\n",
    "import joblib\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Step 04: Load Dataset\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "file_name = 'StudentPerformanceFactors.csv'\n",
    "df = pd.read_csv(file_name)\n",
    "print(f\"Loaded dataset with shape: {df.shape}\")\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Step 05: Initial Exploration\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "print(df.head(), '\\n')\n",
    "print(df.info(), '\\n')\n",
    "print(df.describe().T, '\\n')\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Step 06: Create Categorical Target from Exam_Score\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "bins   = [0, 60, 70, np.inf]\n",
    "labels = ['Low', 'Medium', 'High']\n",
    "df['Exam_Category'] = pd.cut(df['Exam_Score'], bins=bins, labels=labels)\n",
    "print(df['Exam_Category'].value_counts(), '\\n')\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Step 07: Handle Missing Values\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "num_cols = df.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "cat_cols = df.select_dtypes(include=['object','category']).columns.drop('Exam_Category').tolist()\n",
    "\n",
    "df[num_cols] = SimpleImputer(strategy='median').fit_transform(df[num_cols])\n",
    "df[cat_cols] = SimpleImputer(strategy='most_frequent').fit_transform(df[cat_cols])\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Step 08: Encode Categorical Variables\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "le = LabelEncoder()\n",
    "for col in cat_cols + ['Exam_Category']:\n",
    "    df[col] = le.fit_transform(df[col].astype(str))\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Step 09: Feature Engineering\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "df['Hours_x_Attendance'] = df['Hours_Studied'] * df['Attendance']\n",
    "# (add any additional engineered features here)\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Step 10: Clustering Behavioral Profiles\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "behav_feats = ['Hours_Studied', 'Attendance', 'Motivation_Level', 'Sleep_Hours']\n",
    "df['Behavior_Cluster'] = KMeans(n_clusters=4, random_state=42).fit_predict(df[behav_feats])\n",
    "print(\"Cluster distribution:\\n\", df['Behavior_Cluster'].value_counts(), '\\n')\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Step 11: Prepare Data for Modeling\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "target    = 'Exam_Category'\n",
    "drop_cols = ['Exam_Score']\n",
    "features  = [c for c in df.columns if c not in drop_cols + [target]]\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "numeric_feats_to_scale = [c for c in num_cols if c in features]\n",
    "scaler = StandardScaler()\n",
    "X_train[numeric_feats_to_scale] = scaler.fit_transform(X_train[numeric_feats_to_scale])\n",
    "X_test[numeric_feats_to_scale]  = scaler.transform(X_test[numeric_feats_to_scale])\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Step 12: Model Training & Hyperparameter Tuning\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "xgb = XGBClassifier(eval_metric='mlogloss', random_state=42)\n",
    "param_grid = {\n",
    "    'n_estimators':   [100, 200],\n",
    "    'max_depth':      [3, 5],\n",
    "    'learning_rate':  [0.01, 0.1]\n",
    "}\n",
    "\n",
    "cv   = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid = GridSearchCV(xgb, param_grid, cv=cv, scoring='f1_macro', n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid.best_params_, '\\n')\n",
    "model = grid.best_estimator_\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Step 13: Evaluation on Test Set\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Test Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "print(\"Test Macro F1:  \", f1_score(y_test, y_pred, average='macro'))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred), '\\n')\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Step 14: Interpretability with SHAP (Fixed)\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "explainer   = shap.TreeExplainer(model)\n",
    "shap_vals   = explainer.shap_values(X_test)\n",
    "\n",
    "# Summary bar plot\n",
    "shap.summary_plot(shap_vals, X_test, plot_type=\"bar\", show=False)\n",
    "plt.tight_layout(); plt.savefig('shap_summary_bar.png'); plt.show()\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Step 15: Save Final Model\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "joblib.dump(model, 'spd_xgb_model.pkl')\n",
    "print(\"Model saved to spd_xgb_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "executionInfo": {
     "elapsed": 266,
     "status": "ok",
     "timestamp": 1749400471561,
     "user": {
      "displayName": "Rakibul Islam Rifat",
      "userId": "07268514922413816101"
     },
     "user_tz": -360
    },
    "id": "2YqF7htK44ow",
    "outputId": "ef48cf48-bfdc-464a-d126-9ea6c261de84"
   },
   "outputs": [],
   "source": [
    "# prompt: visualize confusion matrix\n",
    "\n",
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=le.classes_,\n",
    "            yticklabels=le.classes_)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 703
    },
    "executionInfo": {
     "elapsed": 497,
     "status": "ok",
     "timestamp": 1749400472057,
     "user": {
      "displayName": "Rakibul Islam Rifat",
      "userId": "07268514922413816101"
     },
     "user_tz": -360
    },
    "id": "2ueC0iLQB5xZ",
    "outputId": "ac47de75-41cf-46d5-8d20-8fb823c1893a"
   },
   "outputs": [],
   "source": [
    "# prompt: visualize roc curve\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Step 16: Visualize ROC Curve\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Binarize the output\n",
    "y_test_bin = label_binarize(y_test, classes=[0, 1, 2])\n",
    "n_classes = y_test_bin.shape[1]\n",
    "# Get predicted probabilities for each class\n",
    "y_prob = model.predict_proba(X_test)\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_prob[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "# Plot all ROC curves\n",
    "plt.figure(figsize=(10, 8))\n",
    "lw = 2\n",
    "colors = ['blue', 'red', 'green']\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'.format(le.classes_[i], roc_auc[i]))\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve for Multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('roc_curve.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1749400472061,
     "user": {
      "displayName": "Rakibul Islam Rifat",
      "userId": "07268514922413816101"
     },
     "user_tz": -360
    },
    "id": "R4OhUgDcB-pc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NdRLh89yYebF"
   },
   "source": [
    "Exam Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1749400472069,
     "user": {
      "displayName": "Rakibul Islam Rifat",
      "userId": "07268514922413816101"
     },
     "user_tz": -360
    },
    "id": "AcRK7-x5XSqA",
    "outputId": "3b85c485-a917-4717-8c71-605420d5e623"
   },
   "outputs": [],
   "source": [
    "# Instead of just typing 'Exam_Category', access it from the DataFrame:\n",
    "# To see the value counts of the 'Exam_Category' column\n",
    "print(df['Exam_Category'].value_counts())\n",
    "\n",
    "# To see the first few entries of the 'Exam_Category' column\n",
    "# print(df['Exam_Category'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w-52zEC7YUpo"
   },
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 770
    },
    "executionInfo": {
     "elapsed": 49,
     "status": "ok",
     "timestamp": 1749400472121,
     "user": {
      "displayName": "Rakibul Islam Rifat",
      "userId": "07268514922413816101"
     },
     "user_tz": -360
    },
    "id": "BVaVLlrDYqe2",
    "outputId": "f6a21e3a-d326-4063-8f58-d46794ca7562"
   },
   "outputs": [],
   "source": [
    "df.describe().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 49,
     "status": "ok",
     "timestamp": 1749401616073,
     "user": {
      "displayName": "Rakibul Islam Rifat",
      "userId": "07268514922413816101"
     },
     "user_tz": -360
    },
    "id": "vj0XL0yadTuG",
    "outputId": "5093084c-113c-4ab0-fdee-481baa149dd3"
   },
   "outputs": [],
   "source": [
    "# prompt: macro F1-score\n",
    "\n",
    "print(\"Test Macro F1:  \", f1_score(y_test, y_pred, average='macro'))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN0FoGfyZ1YQEJMsRo913E1",
   "mount_file_id": "1MpmHTHtWilf6djovPsQVKSaszTnyVg6K",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
